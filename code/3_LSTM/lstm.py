# -*- coding: utf-8 -*-
"""LSTM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1px18s7naimUiRW48sX21IO65-ThZ01Vb
"""

# 获取Google网盘的访问权限

from google.colab import drive
drive.mount('/content/gdrive')

import torch 
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Hyper-parameters
sequence_length = 128
input_size = 128*3
hidden_size = 128*3*4
num_layers = 2
num_classes = 19
# batch_size = 100
batch_size = 10
num_epochs = 20 #32
#learning_rate = 0.01
learning_rate = 0.00005

# 加载训练集与测试集

train_txt_path = './gdrive/My Drive/remote/RSDataset/train.txt'
test_txt_path = './gdrive/My Drive/remote/RSDataset/test.txt'

class MyDataset(Dataset):
    def __init__(self, txt_path, transform = None, target_transform = None):
        fh = open(txt_path, 'r')
        imgs = []
        for line in fh:
            line = line.rstrip()
            words = line.split()
            imgs.append((words[0]+' '+words[1],int(words[2])))

        self.imgs = imgs        # 最主要就是要生成这个list， 然后DataLoader中给index，通过getitem读取图片数据
        self.transform = transform
        self.target_transform = target_transform

    def __getitem__(self, index):
        fn, label = self.imgs[index]
        img = Image.open(fn).convert('RGB')     # 像素值 0~255，在transfrom.totensor会除以255，使像素值变成 0~1

        if self.transform is not None:
            img = self.transform(img)   # 在这里做transform，转为tensor等等

        return img, label

    def __len__(self):
        return len(self.imgs)
      
train_data = MyDataset(txt_path=train_txt_path, transform = transform)
train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
test_data = MyDataset(txt_path=test_txt_path, transform = transform)
test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)

# Recurrent neural network (many-to-one)
class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):
        super(RNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5) #dropout=0.5
        self.fc = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        # Set initial hidden and cell states 
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) 
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        
        # Forward propagate LSTM
        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)
        
        # Decode the hidden state of the last time step
        out = self.fc(out[:, -1, :])
        return out

# Loss criterion
criterion = nn.CrossEntropyLoss()

# Train the model

def train(model, train_loader, num_epochs, sequence_length, input_size, device, learning_rate):

    
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    Loss_list = []
    j = 0;


    total_step = len(train_loader)
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            images = images.reshape(-1, sequence_length, input_size).to(device)
            #labels = class_label.index(labels)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i+1) % 10 == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
                Loss_list.append(loss.item())
                j = j+1
    x = range(j)
    plt.plot(x, Loss_list, '.-')

# Test the model

def test(model, test_loader, sequence_length, input_size, device):

    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.reshape(-1, sequence_length, input_size).to(device)
            labels = labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        print('Test Accuracy of the model on test images: {} %'.format(100 * correct / total)) 
        print('Loss: ',loss.item())
        return (100 * correct / total)

# 对LSTM进行训练和测试

model = RNN(input_size, hidden_size, num_layers, num_classes, dropout=0.5).to(device)
train(model, train_loader, num_epochs, sequence_length, input_size, device, learning_rate)# learning_rate
test(model, test_loader, sequence_length, input_size, device)

# 观察learning rate和dropout的取值对LSTM模型的训练效果的影响

dropout = [0.3, 0.5, 0.7]
learning_rate = [0.000005,0.00005,0.0005]
accuracy = { }
for i,lr in enumerate(learning_rate):
  for j, dp in enumerate(dropout):
    model = RNN(input_size, hidden_size, num_layers, num_classes, dropout=dp).to(device)
    train(model, train_loader, num_epochs, sequence_length, input_size, device, lr)
    test_accuracy = test(model, test_loader, sequence_length, input_size, device)
    accuracy[(lr, dp)] = test_accuracy

for lr, dp in sorted(accuracy):
  test_accuracy = accuracy[(lr, dp)]
  print('lr %e dp %e test accuracy: %f' % (lr, dp, test_accuracy))
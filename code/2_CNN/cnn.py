# -*- coding: utf-8 -*-
"""CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DZ-cy3u2cXsAtl-ufHdOH2VrXu5GkteN
"""

# 获取Google网盘的访问权限

from google.colab import drive
drive.mount('/content/gdrive')

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import Dataset
from PIL import Image
import matplotlib.pyplot as plt

# 参数设置

BATCH_SIZE = 10
EPOCHS = 10
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.Resize(128),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    
])

# 加载训练集与测试集

train_txt_path = './gdrive/My Drive/remote/RSDataset/train.txt'
test_txt_path = './gdrive/My Drive/remote/RSDataset/test.txt'

class MyDataset(Dataset):
    def __init__(self, txt_path, transform = None, target_transform = None):
        fh = open(txt_path, 'r')
        imgs = []
        for line in fh:
            line = line.rstrip()
            words = line.split()
            imgs.append((words[0]+' '+words[1],int(words[2])))

        self.imgs = imgs        # 最主要就是要生成这个list， 然后DataLoader中给index，通过getitem读取图片数据
        self.transform = transform
        self.target_transform = target_transform

    def __getitem__(self, index):
        fn, label = self.imgs[index]
        img = Image.open(fn).convert('RGB')     # 像素值 0~255，在transfrom.totensor会除以255，使像素值变成 0~1

        if self.transform is not None:
            img = self.transform(img)   # 在这里做transform，转为tensor等等

        return img, label

    def __len__(self):
        return len(self.imgs)
      
train_data = MyDataset(txt_path=train_txt_path, transform = transform)
train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)
test_data = MyDataset(txt_path=test_txt_path, transform = transform)
test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)

# 构建CNN类

class CNN_net_1(nn.Module):
    def __init__(self):
        super(CNN_net_1, self).__init__()
        self.conv1 = nn.Conv2d(3, 10, 5)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(10, 20, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(20*29*29, 1000)
        self.fc2 = nn.Linear(1000, 19)
        self.dropout=nn.Dropout()

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x))) # 62*62*10
        x = self.pool2(F.relu(self.conv2(x))) # 29*29*20
        x = x.view(-1, 20*29*29)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.log_softmax(self.fc2(x), dim=1)
        return x

# 实例化CNN模型

model = CNN_net_1().to(DEVICE)
optimizer = optim.Adam(model.parameters())

# 训练函数

def train(model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if (batch_idx + 1) % 10 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))

# 测试函数

def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target,
                                    reduction='sum').item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    print(
        '\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\n'.format(
            test_loss, correct, len(test_loader.dataset),
            100. * correct / len(test_loader.dataset)))
    return (float(correct) / len(test_loader.dataset))

# 进行训练并输出结果

result = []
for epoch in range(1, EPOCHS + 1):
    train(model, DEVICE, train_loader, optimizer, epoch)
    accuracy = test(model, DEVICE, test_loader)
    result.append(accuracy)

plt.plot(range(1,11),result)
plt.xticks(range(1,11))
plt.xlabel('epoch')
plt.ylabel('test accuracy')
plt.title('CNN')

# 尝试相同深度但是卷积核数量更多的卷积网络模型

class CNN_net_2(nn.Module):
    def __init__(self):
        super(CNN_net_2, self).__init__()
        self.conv1 = nn.Conv2d(3, 20, 5)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(20, 80, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(80*29*29, 2000)
        self.fc2 = nn.Linear(2000, 19)
        self.dropout=nn.Dropout()

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(-1, 80*29*29)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.log_softmax(self.fc2(x), dim=1)
        return x

# 尝试层数+1的卷积网络模型

class CNN_net_3(nn.Module):
    def __init__(self):
        super(CNN_net_3, self).__init__()
        self.conv1 = nn.Conv2d(3, 10, 3)
        self.pool1 = nn.MaxPool2d(3, 3)
        self.conv2 = nn.Conv2d(10, 20, 3)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.conv3 = nn.Conv2d(20,40,3)
        self.pool3 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(40*9*9, 250)
        self.fc2 = nn.Linear(250, 19)
        self.dropout=nn.Dropout()

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x))) 
        x = self.pool2(F.relu(self.conv2(x))) 
        x = self.pool3(F.relu(self.conv3(x)))
        x = x.view(-1, 40*9*9)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.log_softmax(self.fc2(x), dim=1)
        return x

# 实例化两个新的网络结构

model_2 = CNN_net_2().to(DEVICE)
model_3 = CNN_net_3().to(DEVICE)

# 对model_2进行训练并输出结果

result = []
for epoch in range(1, EPOCHS + 1):
    train(model_2, DEVICE, train_loader, optimizer, epoch)
    accuracy = test(model_2, DEVICE, test_loader)
    result.append(accuracy)

plt.plot(range(1,EPOCHS + 1),result)
plt.xticks(range(1,EPOCHS + 1))
plt.xlabel('epoch')
plt.ylabel('test accuracy')
plt.title('CNN_net_2')

# 对model_2进行训练并输出结果

result = []
for epoch in range(1, EPOCHS + 1):
    train(model_3, DEVICE, train_loader, optimizer, epoch)
    accuracy = test(model_3, DEVICE, test_loader)
    result.append(accuracy)

plt.plot(range(1,EPOCHS + 1),result)
plt.xticks(range(1,EPOCHS + 1))
plt.xlabel('epoch')
plt.ylabel('test accuracy')
plt.title('CNN_net_3')